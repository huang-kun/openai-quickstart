{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "439df52a-dadf-4fd8-a0ad-e59bac7ca529",
   "metadata": {},
   "source": [
    "# 使用 LangChain 构建一个 RAG 应用\n",
    "\n",
    "## RAG 是什么\n",
    "\n",
    "RAG 是一种将检索到的文档上下文与大语言模型（LLM）结合起来生成答案的技术。\n",
    "\n",
    "整个过程主要分为以下几个步骤：\n",
    "\n",
    "1. 加载文档：将原始数据(来源可能是在线网站、本地文件、各类平台等)加载到 LangChain 中。\n",
    "1. 文档分割：将加载的文档分割成较小的块，以适应模型的上下文窗口，并更容易进行向量嵌入和检索。\n",
    "1. 存储嵌入：将分割后的文档内容嵌入到向量空间，并存储到向量数据库中，以便后续检索。\n",
    "1. 检索文档：通过查询向量数据库，检索与问题最相关的文档片段。\n",
    "1. 生成回答：将检索到的文档片段与用户问题组合，生成并返回答案。\n",
    "\n",
    "通过这些步骤，可以构建一个强大的问答系统，将复杂任务分解为更小的步骤并生成详细回答。\n",
    "\n",
    "![rag](../images/rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d81c83-4083-4ec1-ac4c-e96840024278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a5b694-e332-4311-a20f-4e55fc9e3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: langchain_community in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (0.2.0)\n",
      "Collecting langchain_chroma\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bc/8c/ef0a589e523e72373a79a64cd1184682155113b865f889d815a9f264a755/langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (0.1.65)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (0.2.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (3.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain_chroma) (0.4.24)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain_chroma) (0.115.5)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.68.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.66.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.7.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.2.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.9.0)\n",
      "Requirement already satisfied: build>=1.0.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: typer>=0.9.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.13.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.32.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (31.0.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: importlib-resources in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.4.5)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.0.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.20.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.7.2)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: orjson>=3.9.12 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.10.11)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.41.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.4.6)\n",
      "Requirement already satisfied: tomli>=1.1.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.1.0)\n",
      "Requirement already satisfied: pyproject_hooks in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: requests-oauthlib in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.36.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.9)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.8.2)\n",
      "Requirement already satisfied: coloredlogs in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
      "Requirement already satisfied: protobuf in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.28.3)\n",
      "Requirement already satisfied: sympy in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.5.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-proto==1.28.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.28.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.28.2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.49b2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.49b2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.49b2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.49b2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.49b2->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain_chroma) (4.6.2.post1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.26.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (13.9.4)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.4)\n",
      "Requirement already satisfied: websockets>=10.4 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (11.0.3)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.24.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi<1,>=0.95.2->langchain_chroma) (1.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2024.10.0)\n",
      "Requirement already satisfied: filelock in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.16.1)\n",
      "Requirement already satisfied: zipp>=3.20 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.18.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
      "Installing collected packages: langchain_chroma\n",
      "Successfully installed langchain_chroma-0.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community langchain_chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b363d-c56e-420e-b8c1-76420b6cfa46",
   "metadata": {},
   "source": [
    "## **RAG 开发指南**\n",
    "\n",
    "**本指南将详细介绍如何使用 LangChain 框架构建一个基于检索增强生成 (RAG) 的应用。**\n",
    "\n",
    "下面是基于 LangChain 实现的 RAG 的核心步骤与使用到的关键代码抽象（类型、方法、库等）:\n",
    "\n",
    "1. **加载文档**: 使用 `WebBaseLoader` 类从指定来源加载内容，并生成 `Document` 对象（依赖 `bs4` 库）。\n",
    "2. **文档分割**: 使用 `RecursiveCharacterTextSplitter` 类的 `split_documents()` 方法将长文档分割成较小的块。\n",
    "3. **存储嵌入**: 使用 `Chroma` 类的 `from_documents()` 方法将分割后的文档内容嵌入向量空间，并存储在向量数据库中（使用 `OpenAIEmbeddings`），并可以通过检查存储的向量数量来确认存储成功。。\n",
    "4. **检索文档**: 使用 `VectorStoreRetriever` 类的 `as_retriever()` 和 `invoke()` 方法基于查询从向量数据库中检索最相关的文档片段。\n",
    "5. **生成回答**: 使用 `ChatOpenAI` 类的 `invoke()` 方法，将检索到的文档片段与用户问题结合，生成回答（通过 `RunnablePassthrough` 和 `StrOutputParser`）。\n",
    "\n",
    "我们使用的文档是Lilian Weng撰写的《LLM Powered Autonomous Agents》博客文章（https://lilianweng.github.io/posts/2023-06-23-agent/ ），最终构建好的 RAG 应用支持我们询问关于该文章内容的相关问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd5318a1-2bb9-45bb-8206-82fcf024c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd3284-1cd1-4f53-b105-7f4f5d70faf3",
   "metadata": {},
   "source": [
    "### Step 1: 加载文档\n",
    "\n",
    "- **描述**: 使用 `DocumentLoader` 从指定来源（如网页）加载内容，并将其转换为 `Document` 对象。\n",
    "- **重要代码抽象**:\n",
    "  - 类: `WebBaseLoader`\n",
    "  - 方法: `load()`\n",
    "  - 库: `bs4` (BeautifulSoup)\n",
    "- **代码解释**:\n",
    "  - **文档加载**: 使用 `WebBaseLoader` 从网页加载内容，并通过 `BeautifulSoup` 解析 HTML，提取重要的部分。\n",
    "  - **检查加载数量**: 打印加载的文档数量，确保所有文档正确加载。\n",
    "  - **验证文档内容**: 输出第一个文档的部分内容，确认加载的数据符合预期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6ccef98-31df-4a7d-a5d1-94785651e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 WebBaseLoader 从网页加载内容，并仅保留标题、标题头和文章内容\n",
    "bs4_strainer = bs4.SoupStrainer(id=(\"page-title\", \"main-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.ruanyifeng.com/blog/2014/11/compiler.html\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e5c2d11-eff2-43d1-8800-9d9d3a301f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4841\n"
     ]
    }
   ],
   "source": [
    "# 检查加载的文档内容长度\n",
    "print(len(docs[0].page_content))  # 打印第一个文档内容的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d94fd046-6a2a-4761-a83b-a9f82ed53b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编译器的工作过程\n",
      "\n",
      "源码要运行，必须先转成二进制的机器码。这是编译器的任务。\n",
      "\n",
      "\n",
      "比如，下面这段源码（假定文件名叫做test.c）。\n",
      "\n",
      "#include <stdio.h>\n",
      "\n",
      "int main(voi\n"
     ]
    }
   ],
   "source": [
    "# 查看第一个文档（前100字符）\n",
    "print(docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26600ceb-0de8-4820-b438-ed8ae561886f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b6705c5-54ab-4cbd-9718-01563257e54d",
   "metadata": {},
   "source": [
    "### Step 2: 文档分割\n",
    "\n",
    "- **描述**: 使用文本分割器将加载的长文档分割成较小的块，以便嵌入和检索。\n",
    "- **重要代码抽象**:\n",
    "  - 类: `RecursiveCharacterTextSplitter`\n",
    "  - 方法: `split_documents()`\n",
    "- **代码解释**:\n",
    "  - **文档分割**: 使用 `RecursiveCharacterTextSplitter` 按字符大小分割文档块，设置块大小和重叠字符数，确保文档块适合模型处理。\n",
    "  - **检查块数量**: 打印分割后的文档块数量，确保分割操作正确执行。\n",
    "  - **验证块大小**: 输出第一个块的字符数，确认分割块的大小是否符合预期。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0958c3b5-4110-44b2-9e27-4a82015c0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 RecursiveCharacterTextSplitter 将文档分割成块，每块1000字符，重叠200字符\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=20, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "04d73830-8e73-4293-80b0-7e631f7344d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "# 检查分割后的块数量和内容\n",
    "print(len(all_splits))  # 打印分割后的文档块数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5263f892-4a80-42b9-b79e-ac3e303a60ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "print(len(all_splits[0].page_content))  # 打印第一个块的字符数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46183c0c-91ec-4609-b7c3-e85c08d8d975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编译器的工作过程\n",
      "\n",
      "源码要运行，必须先转成二进制的机器码。这是编译器的任务。\n",
      "\n",
      "\n",
      "比如，下面这段源码（假定文件名叫做test.c）。\n",
      "\n",
      "#include <stdio.h>\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[0].page_content)  # 打印第一个块的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "034ce612-96d0-4b61-8d53-884b48a85a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://www.ruanyifeng.com/blog/2014/11/compiler.html', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[0].metadata)  # 打印第一个块的元数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b96fb11-41cb-4d79-b7ec-cc294187baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d04622f-7e3c-413c-89cd-5eef87949966",
   "metadata": {},
   "source": [
    "### Step 3: 存储嵌入\n",
    "\n",
    "- **描述**: 将分割后的文档内容嵌入到向量空间中，并存储到向量数据库，以便后续检索。\n",
    "- **重要代码抽象**:\n",
    "  - 类: `Chroma`\n",
    "  - 方法: `from_documents()`\n",
    "  - 类: `OpenAIEmbeddings`\n",
    "- **代码解释**:\n",
    "  - **存储嵌入**: 使用 `Chroma.from_documents()` 方法将所有分割的文档片段进行嵌入(`OpenAIEmbeddings`嵌入模型)，将文档片段嵌入向量空间，并存储在向量数据库中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f1eca-7d0c-4bcc-b255-054cc002d7f4",
   "metadata": {},
   "source": [
    "#### Chroma 基础使用\n",
    "\n",
    "**下面是初始化 Chroma 数据库（仅实例化，未存储向量数据）的常见做法：**\n",
    "\n",
    "**使用构造函数初始化**: 在本地持久化存储 Chroma 数据库.\n",
    "\n",
    "```python\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not neccesary\n",
    ")\n",
    "```\n",
    "\n",
    "**使用 Cleint 初始化**: 更方便地访问底层数据库/集合。\n",
    "\n",
    "```python\n",
    "import chromadb\n",
    "\n",
    "persistent_client = chromadb.PersistentClient()\n",
    "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
    "collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
    "\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"collection_name\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "**我们直接使用 `Chroma.from_documents()` 方法 实例化+数据存储**:\n",
    "\n",
    "该方法返回 Chroma 实例，数据类型为`langchain_chroma.vectorstores.Chroma`，详细 API 文档： https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef288a05-25a4-4f2f-827a-a5f318ff0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Chroma 向量存储和 OpenAIEmbeddings 模型，将分割的文档块嵌入并存储\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39aa3545-b456-473a-b620-5fb0eab15dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_chroma.vectorstores.Chroma"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看 vectorstore 数据类型\n",
    "type(vectorstore) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b52313-646a-4512-8125-68054c1c7e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6c587ce-b40f-47ad-bd14-480c49a073e7",
   "metadata": {},
   "source": [
    "### Step 4: 检索文档\n",
    "\n",
    "- **描述**: 使用 `VectorStoreRetriever` 类的 `as_retriever()` 和 `invoke()` 方法，从向量数据库中检索与查询最相关的文档片段。\n",
    "- **重要代码抽象**:\n",
    "  - 类: `VectorStoreRetriever`\n",
    "  - 方法: `as_retriever()`, `invoke()`\n",
    "- **代码解释**:\n",
    "  - **文档检索**: 将向量存储转换为检索器，并基于查询执行相似性搜索，获取相关文档片段。\n",
    "  - **检查检索数量**: 打印检索到的文档片段数量，确保检索操作成功。\n",
    "  - **验证检索内容**: 输出第一个检索到的文档内容，确认检索结果与预期相符。\n",
    "\n",
    "在 LangChain 中，所有向量数据库都支持**vectorstore.as_retriever** 方法，实例化该数据库对应的检索器（Retriever），数据类型为`VectorStoreRetriever`，详细 API 文档：https://python.langchain.com/v0.2/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStoreRetriever.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0cdab30e-b07d-4273-b734-3aabff356bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 VectorStoreRetriever 从向量存储中检索与查询最相关的文档\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6feddb48-d07e-40be-a9fe-790c3bb75d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.VectorStoreRetriever"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9283b2e6-874f-4815-915b-e87da0429a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"什么是编译？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d292f13-9581-4f28-b54d-ba0fe9fa0040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# 检查检索到的文档内容\n",
    "print(len(retrieved_docs))  # 打印检索到的文档数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "458d6a7d-21a9-49a4-b523-651e3bab51e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第六步 编译（Compilation）\n",
      "预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[0].page_content)  # 打印第一个检索到的文档内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6cdc6302-1b59-4abc-813a-6b0d44cc7cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第六步 编译（Compilation）\n",
      "预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。\n",
      "---------------\n",
      "这些命令到底在干什么？大多数的书籍和资料，都语焉不详，只说这样就可以编译了，没有进一步的解释。\n",
      "---------------\n",
      "数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做\"配置\"（configure）。\n",
      "---------------\n",
      "编译器的工作过程\n",
      "\n",
      "源码要运行，必须先转成二进制的机器码。这是编译器的任务。\n",
      "\n",
      "\n",
      "比如，下面这段源码（假定文件名叫做test.c）。\n",
      "\n",
      "#include <stdio.h>\n",
      "---------------\n",
      "这一步称为\"预处理\"（Preprocessing），因为完成之后，就要开始真正的处理了。\n",
      "第六步 编译（Compilation）\n",
      "---------------\n",
      "件只需编译一次，不必每次用到的时候，都重新编译了。\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for rdoc in retrieved_docs:\n",
    "    print(rdoc.page_content)\n",
    "    print(\"---------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3309c1e-c650-44ae-baba-6f7528372931",
   "metadata": {},
   "source": [
    "### Step 5: 生成回答\n",
    "\n",
    "- **描述**: 将之前构建的组件（检索器、提示、LLM等）组合成一个完整的链条，实现用户问题的检索与生成回答。完整链条：输入用户问题，检索相关文档，构建提示，将其传递给模型（使用`ChatOpenAI` 类的 `invoke()` 方法），并解析输出生成最终回答。\n",
    "- **重要代码抽象**:\n",
    "  - 类: `ChatOpenAI`\n",
    "  - 方法: `invoke()`\n",
    "  - 类: `RunnablePassthrough`\n",
    "  - 类: `StrOutputParser`\n",
    "  - 模块：`hub`\n",
    "- **代码解释**:\n",
    "  - **模型初始化**: 使用 `ChatOpenAI` 类初始化一个 `GPT-4o-mini` 模型，准备处理生成任务。\n",
    "  - **文档格式化**: 定义 `format_docs` 函数，用于将检索到的文档内容格式化为字符串。\n",
    "  - **构建 RAG 链**: 使用 LCEL (LangChain Execution Layer) 的 `|` 操作符将各个组件连接成一个链条，包括文档检索、提示构建、模型调用以及输出解析。\n",
    "  - **生成回答**: 使用 `stream()` 方法逐步输出生成的回答，并实时展示，确保生成的结果符合预期。\n",
    "\n",
    "![retrieval](../images/retrieval.png)\n",
    "\n",
    "#### LangChain Hub\n",
    "\n",
    "`LangChain Hub` (https://smith.langchain.com/hub) 是一个提示词模板开源社区，为开发者提供了大量开箱即用的提示词模板。属于 `LangSmith` 产品的一部分。\n",
    "\n",
    "下面我们尝试使用 RAG 应用的提示词模板：https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "\n",
    "\n",
    "```\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3dbe88b-7a8f-4607-8426-698a3adf3ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 RAG 链，将用户问题与检索到的文档结合并生成答案\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "488e8c40-a304-4538-a84e-cc8e4e7e101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\dev\\agent\\openai-quickstart\\.venv\\lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "# 使用 hub 模块拉取 rag 提示词模板\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf0de4c1-e389-430b-a472-521960e12b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "# 打印模板\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "281d2ea1-0a61-45aa-810d-6b80a7d102a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为 context 和 question 填充样例数据，并生成 ChatModel 可用的 Messages\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": docs[0].page_content, \"question\": \"什么是编译？\"}\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e55e098-5f2d-4ef6-98e2-b1a4f27fa853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: 什么是编译？ \n",
      "Context: 编译器的工作过程\n",
      "\n",
      "源码要运行，必须先转成二进制的机器码。这是编译器的任务。\n",
      "\n",
      "\n",
      "比如，下面这段源码（假定文件名叫做test.c）。\n",
      "\n",
      "#include <stdio.h>\n",
      "\n",
      "int main(void)\n",
      "{\n",
      "  fputs(\"Hello, world!\\n\", stdout);\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "要先用编译器处理一下，才能运行。\n",
      "\n",
      "$ gcc test.c\n",
      "$ ./a.out\n",
      "Hello, world!\n",
      "\n",
      "对于复杂的项目，编译过程还必须分成三步。\n",
      "\n",
      "$ ./configure\n",
      "$ make  \n",
      "$ make install\n",
      "\n",
      "这些命令到底在干什么？大多数的书籍和资料，都语焉不详，只说这样就可以编译了，没有进一步的解释。\n",
      "本文将介绍编译器的工作过程，也就是上面这三个命令各自的任务。我主要参考了Alex Smith的文章《Building C Projects》。需要声明的是，本文主要针对gcc编译器，也就是针对C和C++，不一定适用于其他语言的编译。\n",
      "\n",
      "第一步 配置（configure）\n",
      "编译器在开始工作之前，需要知道当前的系统环境，比如标准库在哪里、软件的安装位置在哪里、需要安装哪些组件等等。这是因为不同计算机的系统环境不一样，通过指定编译参数，编译器就可以灵活适应环境，编译出各种环境都能运行的机器码。这个确定编译参数的步骤，就叫做\"配置\"（configure）。\n",
      "这些配置信息保存在一个配置文件之中，约定俗成是一个叫做configure的脚本文件。通常它是由autoconf工具生成的。编译器通过运行这个脚本，获知编译参数。\n",
      "configure脚本已经尽量考虑到不同系统的差异，并且对各种编译参数给出了默认值。如果用户的系统环境比较特别，或者有一些特定的需求，就需要手动向configure脚本提供编译参数。\n",
      "\n",
      "$ ./configure --prefix=/www --with-mysql\n",
      "\n",
      "上面代码是php源码的一种编译配置，用户指定安装后的文件保存在www目录，并且编译时加入mysql模块的支持。\n",
      "第二步 确定标准库和头文件的位置\n",
      "源码肯定会用到标准库函数（standard library）和头文件（header）。它们可以存放在系统的任意目录中，编译器实际上没办法自动检测它们的位置，只有通过配置文件才能知道。\n",
      "编译的第二步，就是从配置文件中知道标准库和头文件的位置。一般来说，配置文件会给出一个清单，列出几个具体的目录。等到编译时，编译器就按顺序到这几个目录中，寻找目标。\n",
      "第三步 确定依赖关系\n",
      "对于大型项目来说，源码文件之间往往存在依赖关系，编译器需要确定编译的先后顺序。假定A文件依赖于B文件，编译器应该保证做到下面两点。\n",
      "\n",
      "（1）只有在B文件编译完成后，才开始编译A文件。\n",
      "（2）当B文件发生变化时，A文件会被重新编译。\n",
      "\n",
      "编译顺序保存在一个叫做makefile的文件中，里面列出哪个文件先编译，哪个文件后编译。而makefile文件由configure脚本运行生成，这就是为什么编译时configure必须首先运行的原因。\n",
      "在确定依赖关系的同时，编译器也确定了，编译时会用到哪些头文件。\n",
      "第四步 头文件的预编译（precompilation）\n",
      "不同的源码文件，可能引用同一个头文件（比如stdio.h）。编译的时候，头文件也必须一起编译。为了节省时间，编译器会在编译源码之前，先编译头文件。这保证了头文件只需编译一次，不必每次用到的时候，都重新编译了。\n",
      "不过，并不是头文件的所有内容，都会被预编译。用来声明宏的#define命令，就不会被预编译。 \n",
      "第五步 预处理（Preprocessing）\n",
      "预编译完成后，编译器就开始替换掉源码中bash的头文件和宏。以本文开头的那段源码为例，它包含头文件stdio.h，替换后的样子如下。\n",
      "\n",
      "extern int fputs(const char *, FILE *);\n",
      "extern FILE *stdout;\n",
      "\n",
      "int main(void)\n",
      "{\n",
      "    fputs(\"Hello, world!\\n\", stdout);\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "为了便于阅读，上面代码只截取了头文件中与源码相关的那部分，即fputs和FILE的声明，省略了stdio.h的其他部分（因为它们非常长）。另外，上面代码的头文件没有经过预编译，而实际上，插入源码的是预编译后的结果。编译器在这一步还会移除注释。\n",
      "这一步称为\"预处理\"（Preprocessing），因为完成之后，就要开始真正的处理了。\n",
      "第六步 编译（Compilation）\n",
      "预处理之后，编译器就开始生成机器码。对于某些编译器来说，还存在一个中间步骤，会先把源码转为汇编码（assembly），然后再把汇编码转为机器码。\n",
      "下面是本文开头的那段源码转成的汇编码。\n",
      "\n",
      "    .file   \"test.c\"\n",
      "    .section    .rodata\n",
      ".LC0:\n",
      "    .string \"Hello, world!\\n\"\n",
      "    .text\n",
      "    .globl  main\n",
      "    .type   main, @function\n",
      "main:\n",
      ".LFB0:\n",
      "    .cfi_startproc\n",
      "    pushq   %rbp\n",
      "    .cfi_def_cfa_offset 16\n",
      "    .cfi_offset 6, -16\n",
      "    movq    %rsp, %rbp\n",
      "    .cfi_def_cfa_register 6\n",
      "    movq    stdout(%rip), %rax\n",
      "    movq    %rax, %rcx\n",
      "    movl    $14, %edx\n",
      "    movl    $1, %esi\n",
      "    movl    $.LC0, %edi\n",
      "    call    fwrite\n",
      "    movl    $0, %eax\n",
      "    popq    %rbp\n",
      "    .cfi_def_cfa 7, 8\n",
      "    ret\n",
      "    .cfi_endproc\n",
      ".LFE0:\n",
      "    .size   main, .-main\n",
      "    .ident  \"GCC: (Debian 4.9.1-19) 4.9.1\"\n",
      "    .section    .note.GNU-stack,\"\",@progbits\n",
      "\n",
      "这种转码后的文件称为对象文件（object file）。\n",
      "第七步 连接（Linking）\n",
      "对象文件还不能运行，必须进一步转成可执行文件。如果你仔细看上一步的转码结果，会发现其中引用了stdout函数和fwrite函数。也就是说，程序要正常运行，除了上面的代码以外，还必须有stdout和fwrite这两个函数的代码，它们是由C语言的标准库提供的。\n",
      "编译器的下一步工作，就是把外部函数的代码（通常是后缀名为.lib和.a的文件），添加到可执行文件中。这就叫做连接（linking）。这种通过拷贝，将外部函数库添加到可执行文件的方式，叫做静态连接（static linking），后文会提到还有动态连接（dynamic linking）。\n",
      "make命令的作用，就是从第四步头文件预编译开始，一直到做完这一步。\n",
      "第八步 安装（Installation）\n",
      "上一步的连接是在内存中进行的，即编译器在内存中生成了可执行文件。下一步，必须将可执行文件保存到用户事先指定的安装目录。\n",
      "表面上，这一步很简单，就是将可执行文件（连带相关的数据文件）拷贝过去就行了。但是实际上，这一步还必须完成创建目录、保存文件、设置权限等步骤。这整个的保存过程就称为\"安装\"（Installation）。\n",
      "第九步 操作系统连接\n",
      "可执行文件安装后，必须以某种方式通知操作系统，让其知道可以使用这个程序了。比如，我们安装了一个文本阅读程序，往往希望双击txt文件，该程序就会自动运行。\n",
      "这就要求在操作系统中，登记这个程序的元数据：文件名、文件描述、关联后缀名等等。Linux系统中，这些信息通常保存在/usr/share/applications目录下的.desktop文件中。另外，在Windows操作系统中，还需要在Start启动菜单中，建立一个快捷方式。\n",
      "这些事情就叫做\"操作系统连接\"。make install命令，就用来完成\"安装\"和\"操作系统连接\"这两步。\n",
      "第十步 生成安装包\n",
      "写到这里，源码编译的整个过程就基本完成了。但是只有很少一部分用户，愿意耐着性子，从头到尾做一遍这个过程。事实上，如果你只有源码可以交给用户，他们会认定你是一个不友好的家伙。大部分用户要的是一个二进制的可执行程序，立刻就能运行。这就要求开发者，将上一步生成的可执行文件，做成可以分发的安装包。\n",
      "所以，编译器还必须有生成安装包的功能。通常是将可执行文件（连带相关的数据文件），以某种目录结构，保存成压缩文件包，交给用户。\n",
      "第十一步 动态连接（Dynamic linking）\n",
      "正常情况下，到这一步，程序已经可以运行了。至于运行期间（runtime）发生的事情，与编译器一概无关。但是，开发者可以在编译阶段选择可执行文件连接外部函数库的方式，到底是静态连接（编译时连接），还是动态连接（运行时连接）。所以，最后还要提一下，什么叫做动态连接。\n",
      "前面已经说过，静态连接就是把外部函数库，拷贝到可执行文件中。这样做的好处是，适用范围比较广，不用担心用户机器缺少某个库文件；缺点是安装包会比较大，而且多个应用程序之间，无法共享库文件。动态连接的做法正好相反，外部函数库不进入安装包，只在运行时动态引用。好处是安装包会比较小，多个应用程序可以共享库文件；缺点是用户必须事先安装好库文件，而且版本和安装位置都必须符合要求，否则就不能正常运行。\n",
      "现实中，大部分软件采用动态连接，共享库文件。这种动态共享的库文件，Linux平台是后缀名为.so的文件，Windows平台是.dll文件，Mac平台是.dylib文件。\n",
      "（文章完）\n",
      "=====================================================\n",
      "\n",
      "以下为广告部分。欢迎大家在我的网络日志投放广告，推广自己的产品。今天介绍的是100offer。\n",
      "[赞助商广告]\n",
      "优秀的人才找到合适的归宿，是这个世界最幸福的事情之一。100offer程序员拍卖网站通过创新的拍卖方式，致力于帮助优秀程序员寻找归宿，给予求职者更多更好的职业选择。\n",
      "\n",
      "过去三个月，100offer中成功的求职者，平均薪资涨幅高于30%，在2周内拿到3-5个offer。100offer与传统招聘网站存在极大差异，主要为下：\n",
      "1、只接受部分候选人：100offer目前仅仅接受年薪高于15万，有一二线知名互联网公司工作经验的优秀程序员申请者。\n",
      "2、反向模式：传统招聘网站是写简历投递给多家公司，而这里程序员只需要提交一次简历给offer，待审核通过后，100offer会邀约平台企业来竞拍候选人，产生一次投递数百家互联网公司的效果。拍卖时程序员会接受到来自各公司新鲜热辣的面试邀请，体验与传统网站截然不同。\n",
      "3、绝对隐私：担心自己的隐私被雇主看到是完全不必要的：1、候选人同意面试邀请前，公司是完全看不到候选人的姓名、联系方式等隐私信息。2、拍卖开始前，候选人可以手动屏蔽掉3家公司，他们将永远看不到你的简历！\n",
      "\n",
      "已经有众多大牛程序员通过100offer找到心仪的工作，目前11月候选人在征集中，点击图片注册100offer并提交完整简历的程序员朋友，即可获赠15元亚马逊礼品卡！（活动截止期为2014年12月30日）\n",
      "100offer目前阶段对企业免费，欢迎极客型创业公司和有实力的互联网公司前来注册招聘！\n",
      "（完）\n",
      "\n",
      " \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# 查看提示词\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300cbbc6-aaaa-4f8c-8382-1cbda08d2fe9",
   "metadata": {},
   "source": [
    "#### ⭐️**LCEL 在 RAG 中的应用**⭐️\n",
    "\n",
    "##### **LCEL 概述**\n",
    "\n",
    "LCEL 是 LangChain 中的一个重要概念，它提供了一种统一的接口，允许不同的组件（如 `retriever`, `prompt`, `llm` 等）可以通过统一的 `Runnable` 接口连接起来。每个 `Runnable` 组件都实现了相同的方法，如 `.invoke()`、`.stream()` 或 `.batch()`，这使得它们可以通过 `|` 操作符轻松连接。\n",
    "\n",
    "##### **LCEL 中处理的组件**\n",
    "\n",
    "- **Retriever**: 负责根据用户问题检索相关文档。\n",
    "- **Prompt**: 根据检索到的文档构建提示，供模型生成回答。\n",
    "- **LLM**: 接收提示并生成最终的回答。\n",
    "- **StrOutputParser**: 解析 LLM 的输出，只提取字符串内容，供最终显示。\n",
    "\n",
    "##### **LCEL 运作机制**\n",
    "\n",
    "- **构建链条**: 通过 `|` 操作符，我们可以将多个 `Runnable` 组件连接成一个 `RunnableSequence`。LangChain 会自动将一些对象转换为 `Runnable`，如将 `format_docs` 转换为 `RunnableLambda`，将包含 `\"context\"` 和 `\"question\"` 键的字典转换为 `RunnableParallel`。\n",
    "\n",
    "- **数据流动**: 用户输入的问题会在 `RunnableSequence` 中依次经过各个 `Runnable` 组件。首先，问题会通过 `retriever` 检索相关文档，然后通过 `format_docs` 将这些文档转换为字符串。`RunnablePassthrough` 则直接传递原始问题。最后，这些数据被传递给 `prompt` 来生成完整的提示，供 LLM 使用。\n",
    "\n",
    "##### **LCEL 中的关键操作**\n",
    "\n",
    "- **格式化文档**: `retriever | format_docs` 将问题传递给 `retriever` 生成文档对象，然后通过 `format_docs` 将这些文档格式化为字符串。\n",
    "- **传递问题**: `RunnablePassthrough()` 直接传递原始问题，保持原样。\n",
    "- **构建提示**: `{\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} | prompt` 构建完整的提示。\n",
    "- **运行模型**: `prompt | llm | StrOutputParser()` 运行 LLM 生成回答，并解析输出。\n",
    "\n",
    "#### 使用 LCEL 构建 RAG Chain\n",
    "\n",
    "下面我们将 LCEL 的概念与代码实现结合起来，展示了如何通过一系列 `Runnable` 组件来实现完整的 RAG 流程。通过 LCEL，LangChain 提供了高度模块化和可扩展的开发方式，使复杂任务的实现变得更加简单和高效。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fe460ec-547e-4714-a7dd-bf9dc319b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义格式化文档的函数\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66e6049b-af4d-435d-aded-68d9c80803bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 LCEL 构建 RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2880d17-79ac-4e5c-966b-144d9ee0dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "程序编译一般分为以下几个步骤：  \n",
      "1. 配置（configure）：确定系统环境和编译参数。  \n",
      "2. 编译（Compilation）：将源代码转换为机器码，可能通过中间的汇编语言步骤。  \n",
      "3. 链接（Linking）：将不同的目标文件和库文件合并，生成可执行文件。"
     ]
    }
   ],
   "source": [
    "# 流式生成回答\n",
    "for chunk in rag_chain.stream(\"程序编译分哪几个步骤？\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb6b9b0e-9883-4375-8bc1-ea31f3659172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "静态连接是在编译时将外部函数库直接拷贝到可执行文件中，优点是无需依赖外部库文件。动态连接则是在运行时加载外部库文件，允许多个程序共享同一库文件，节省空间。静态连接适合广泛使用，但生成的文件较大；动态连接灵活但依赖运行时环境。"
     ]
    }
   ],
   "source": [
    "# 流式生成回答\n",
    "for chunk in rag_chain.stream(\"什么是静态连接和动态连接?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a072d01-60b2-46c7-a104-c8a4a3eda0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19c3d53d-6ae2-4e05-878b-6702c10995bd",
   "metadata": {},
   "source": [
    "# Homework\n",
    "1. 使用其他的线上文档或离线文件，重新构建向量数据库，尝试提出3个相关问题，测试 LCEL 构建的 RAG Chain 是否能成功召回。\n",
    "2. 重新设计或在 LangChain Hub 上找一个可用的 RAG 提示词模板，测试对比两者的召回率和生成质量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d91a2d-56e0-4f52-b6a3-dc893583b51f",
   "metadata": {},
   "source": [
    "### 自定义 Prompt 的示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "94c5d89d-d642-41cb-ab6f-6ead404b6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 自定义提示词模板\n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "template = \"\"\"你是一个高级程序架构师，熟悉计算机软硬件知识，精通计算机底层架构。用通俗且专业的话语回答用户关于计算机的问题。建议优先参考提供的上下文内容来回复，不要杜撰虚假回答，实事求是，不知道答案也可以。\n",
    "问题：{question} \n",
    "上下文：{context} \n",
    "Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "985266bc-1239-45b1-ab76-d7bd2f279cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个高级程序架构师，熟悉计算机软硬件知识，精通计算机底层架构。用通俗且专业的话语回答用户关于计算机的问题。建议优先参考提供的上下文内容来回复，不要杜撰虚假回答，实事求是，不知道答案也可以。\n",
      "问题：filler question \n",
      "上下文：filler context \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# 为 context 和 question 填充样例数据，生成 LLM 可用的提示词\n",
    "print(custom_rag_prompt.invoke({\"context\": \"filler context\", \"question\": \"filler question\"}).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7fbe82ee-de48-4cc8-875c-d74242ef273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新自定义 RAG Chain\n",
    "custom_rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b818824-5a44-461a-b6d5-3ff079beaaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'程序编译通常分为以下几个步骤：\\n\\n1. **预处理（Preprocessing）**：\\n   在编译开始前，源代码会经过预处理阶段。预处理器处理一些预定义的宏（如`#define`），包含头文件（如`#include`），以及条件编译指令等。这一阶段生成的代码不再包含这些指令，只有纯净的源代码供编译器进一步处理。\\n\\n2. **配置（Configure）**：\\n   对于较复杂的项目，尤其是跨平台编译时，编译器需要了解当前系统的环境，包括标准库的位置、系统架构、依赖项等。通过执行`./configure`脚本，编译器可以根据系统环境来设置合适的编译参数，使得编译出的程序能适应目标环境。\\n\\n3. **编译（Compilation）**：\\n   编译器将预处理后的源代码转化为中间代码。通常，编译器会先将源代码转为汇编语言，再将汇编代码转换为机器代码。这一阶段的输出是目标文件（`.o`或`.obj`文件），即包含机器指令但还未完全连接的代码。\\n\\n4. **汇编（Assembly）**：\\n   这一步是编译的一部分，源代码被转化为汇编代码。对于某些编译器，汇编是一个独立的过程，但实际上它是编译过程中的一部分。汇编代码是与特定架构相关的低级指令。\\n\\n5. **链接（Linking）**：\\n   在编译过程中，编译器将源代码中的函数调用、变量引用等与相应的目标文件和库进行链接。这一步会把程序的各个部分（如库文件、目标文件等）合并成一个可执行文件（如`.exe`或`a.out`）。如果程序中使用了外部库，链接器会确保这些库正确地连接到最终的可执行文件中。\\n\\n对于一个较复杂的项目，通常使用以下命令：\\n\\n- `./configure`：配置项目的编译环境。\\n- `make`：根据Makefile文件，执行实际的编译和链接过程。\\n- `make install`：将编译好的程序安装到系统指定的目录中。\\n\\n总结来说，程序的编译过程一般包括预处理、配置、编译、汇编和链接等步骤，最后生成可以执行的二进制文件。'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用自定义 prompt 生成回答\n",
    "custom_rag_chain.invoke(\"程序编译分哪几个步骤？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1fa5d-674d-4e1c-a423-303aea90415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流式生成回答\n",
    "for chunk in custom_rag_chain.stream(\"什么是静态连接和动态连接?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b87b6-f83a-4e6f-b5d3-b0c8d5f293e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
